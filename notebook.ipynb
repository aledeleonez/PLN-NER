{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyqWzTfMFgcG"
      },
      "source": [
        "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J1hKFzUFgcI"
      },
      "source": [
        "***\n",
        "Datos del alumno (Nombre y Apellidos): Alejandro de León Fernández\n",
        "\n",
        "Fecha: 13/12/2024\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkg7dFZ3FgcJ"
      },
      "source": [
        "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Named-Entity Recognition</span>\n",
        "\n",
        "**Objetivos**\n",
        "\n",
        "Con esta actividad se tratará de que el alumno se familiarice con el manejo de la librería spacy, así como con los conceptos básicos de manejo de las técnicas NER\n",
        "\n",
        "**Descripción**\n",
        "\n",
        "En esta actividad debes procesar de forma automática un texto en lenguaje natural para detectar características básicas en el mismo, y para identificar y etiquetar las ocurrencias de conceptos como localización, moneda, empresas, etc.\n",
        "\n",
        "En la primera parte del ejercicio se proporciona un código fuente a través del cual se lee un archivo de texto y se realiza un preprocesado del mismo. En esta parte el alumno tan sólo debe ejecutar y entender el código proporcionado.\n",
        "\n",
        "En la segunda parte del ejercicio se plantean una serie de preguntas que deben ser respondidas por el alumno. Cada pregunta deberá responderse con un fragmento de código fuente que esté acompañado de la explicación correspondiente. Para elaborar el código solicitado, el alumno deberá visitar la documentación de la librería spacy, cuyos enlaces se proporcionarán donde corresponda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zquIBOq3FgcK"
      },
      "source": [
        "# Parte 1: carga y preprocesamiento del texto a analizar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLQRkNmPFgcK"
      },
      "source": [
        "Observa las diferentes librerías que se están importando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrWzj42JFgcL"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy import displacy\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjX5khmDG9wz",
        "outputId": "6c619812-ca3d-452f-8993-f9d54921e706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-md==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.7.0/es_core_news_md-3.7.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-md==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6HJm2fJFgcN"
      },
      "source": [
        "El siguiente código simplemente carga y preprocesa el texto. Para ello, lo primero que hace es cargar un modelo de lenguaje previamente entrenado. En este caso, se utiliza <i>es_core_news_md</i>:\n",
        "\n",
        "https://spacy.io/models/es#es_core_news_md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6CvJvXOHJKG"
      },
      "outputs": [],
      "source": [
        "import es_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W019cE6oFgcN"
      },
      "outputs": [],
      "source": [
        "nlp = es_core_news_md.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4hFDY98FgcO"
      },
      "source": [
        "El objeto <i>nlp</i> permite utilizar el modelo de lenguaje cargado, de forma que se puede procesar un texto y obtenerlo en su versión preprocesada. Así, nos permite realizar las diferentes tareas. En este caso, vamos a utilizar el pipeline para hacer un preprocesamiento básico, que consiste en tokenizar el texto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlEOcAGH6-sS",
        "outputId": "30fd5587-d697-4697-c2f7-6d31cbf22742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "XJsuOVStFgcO",
        "outputId": "aa0acf6e-7bf3-4cd7-ff21-26a29c9fd029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      MEDIO SOPORTE                                                URL  \\\n",
              "0  EL PAÍS      WEB  https://elpais.com/deportes/2021-01-20/alcoyan...   \n",
              "1  EL PAÍS      WEB  https://elpais.com/deportes/2021-01-20/alcoyan...   \n",
              "2  EL PAÍS      WEB  https://elpais.com/espana/2021-01-18/comienza-...   \n",
              "3  EL PAÍS      WEB  https://elpais.com/espana/2021-01-18/comienza-...   \n",
              "4  EL PAÍS      WEB  https://elpais.com/espana/2021-01-18/comienza-...   \n",
              "\n",
              "  TIPO DE MENSAJE                               CONTENIDO A ANALIZAR  \\\n",
              "0      COMENTARIO  el barça nunca acaeza ante un segundo b ni ant...   \n",
              "1      COMENTARIO  el real madrid ha puesto punto y final a su an...   \n",
              "2      COMENTARIO  cristina cifuentes podría haber sido la presid...   \n",
              "3      COMENTARIO  habría que reabrir el caso. el supremo se dedi...   \n",
              "4      COMENTARIO  me parece un poco exagerado pedir más de tres ...   \n",
              "\n",
              "  INTENSIDAD TIPO DE ODIO TONO HUMORISTICO MODIFICADOR Unnamed: 9 Unnamed: 10  \\\n",
              "0        3.0        Otros              NaN         NaN        NaN         NaN   \n",
              "1        0.0          NaN              NaN         NaN        NaN         NaN   \n",
              "2        3.0   Ideológico              NaN         NaN        NaN         NaN   \n",
              "3        3.0   Ideológico              NaN         NaN        NaN         NaN   \n",
              "4        3.0   Ideológico               Si         NaN        NaN         NaN   \n",
              "\n",
              "  Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14  Unnamed: 15  \n",
              "0         NaN         NaN         NaN         NaN          NaN  \n",
              "1         NaN         NaN         NaN         NaN          NaN  \n",
              "2         NaN         NaN         NaN         NaN          NaN  \n",
              "3         NaN         NaN         NaN         NaN          NaN  \n",
              "4         NaN         NaN         NaN         NaN          NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d92ab479-f34d-4755-ab8d-363e1e1f2343\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEDIO</th>\n",
              "      <th>SOPORTE</th>\n",
              "      <th>URL</th>\n",
              "      <th>TIPO DE MENSAJE</th>\n",
              "      <th>CONTENIDO A ANALIZAR</th>\n",
              "      <th>INTENSIDAD</th>\n",
              "      <th>TIPO DE ODIO</th>\n",
              "      <th>TONO HUMORISTICO</th>\n",
              "      <th>MODIFICADOR</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>Unnamed: 14</th>\n",
              "      <th>Unnamed: 15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EL PAÍS</td>\n",
              "      <td>WEB</td>\n",
              "      <td>https://elpais.com/deportes/2021-01-20/alcoyan...</td>\n",
              "      <td>COMENTARIO</td>\n",
              "      <td>el barça nunca acaeza ante un segundo b ni ant...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Otros</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EL PAÍS</td>\n",
              "      <td>WEB</td>\n",
              "      <td>https://elpais.com/deportes/2021-01-20/alcoyan...</td>\n",
              "      <td>COMENTARIO</td>\n",
              "      <td>el real madrid ha puesto punto y final a su an...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EL PAÍS</td>\n",
              "      <td>WEB</td>\n",
              "      <td>https://elpais.com/espana/2021-01-18/comienza-...</td>\n",
              "      <td>COMENTARIO</td>\n",
              "      <td>cristina cifuentes podría haber sido la presid...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Ideológico</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EL PAÍS</td>\n",
              "      <td>WEB</td>\n",
              "      <td>https://elpais.com/espana/2021-01-18/comienza-...</td>\n",
              "      <td>COMENTARIO</td>\n",
              "      <td>habría que reabrir el caso. el supremo se dedi...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Ideológico</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EL PAÍS</td>\n",
              "      <td>WEB</td>\n",
              "      <td>https://elpais.com/espana/2021-01-18/comienza-...</td>\n",
              "      <td>COMENTARIO</td>\n",
              "      <td>me parece un poco exagerado pedir más de tres ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Ideológico</td>\n",
              "      <td>Si</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d92ab479-f34d-4755-ab8d-363e1e1f2343')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d92ab479-f34d-4755-ab8d-363e1e1f2343 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d92ab479-f34d-4755-ab8d-363e1e1f2343');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74e7f341-0b54-428e-9a02-5f213d8b08be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74e7f341-0b54-428e-9a02-5f213d8b08be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74e7f341-0b54-428e-9a02-5f213d8b08be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "filename = \"drive/MyDrive/UNIR/datos/comentariosOdio.csv\"\n",
        "lines_number = 20\n",
        "#data = pd.read_csv(filename, delimiter=';')\n",
        "#data = pd.read_csv(filename, delimiter=';',nrows=lines_number)\n",
        "data = pd.read_csv(filename, delimiter=';', encoding='utf-8', low_memory=False)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyW7KIP2FgcP"
      },
      "source": [
        "El código anterior carga el archivo CSV (opcionalmente con un límite de líneas a leer) y genera la variable <i>data</i>, que contiene un Dataframe (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) con los datos leídos del CSV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n6DCp8EFgcP"
      },
      "source": [
        "Te vendrá bien conocer la siguiente documentación:\n",
        "<ul>\n",
        "    <li>https://spacy.io/api/doc</li>\n",
        "    <li>https://spacy.io/api/token</li>\n",
        "    <li>https://spacy.io/api/morphology#morphanalysis</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yd5Q_5TFgcP"
      },
      "source": [
        "### Playground\n",
        "\n",
        "Utiliza este espacio para hacer pruebas y ensayos con las variables generadas con el código previo. A modo de ejemplo, se ofrece código que realiza las siguientes tareas:\n",
        "\n",
        "\n",
        "- leer un número dado de líneas del Dataframe y generar dos listas con los valores (se pueden leer directamente del DataFrame, se muestra el ejemplo como una opción más)\n",
        "- procesar el texto de cada comentario\n",
        "\n",
        "\n",
        "Para procesarlo, hay utilizar el objeto <i>nlp</i> y así obtener objetos de la clase <i>Doc</i> (https://spacy.io/api/doc)\n",
        "\n",
        "Visita la documentación de dicha clase y experimenta probando las diferentes funciones y atributos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kdqCplLxFgcQ",
        "outputId": "57ddaad7-d826-4daa-832d-374dd55aa133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "el\n",
            "real\n",
            "madrid\n",
            "ha\n",
            "puesto\n",
            "punto\n",
            "y\n",
            "final\n",
            "a\n",
            "su\n",
            "andadura\n",
            "en\n",
            "la\n",
            "copa\n",
            "del\n",
            "rey\n",
            "en\n",
            "el\n",
            "primer\n",
            "escalón\n",
            ".\n",
            "los\n",
            "de\n",
            "zidane\n",
            "han\n",
            "caído\n",
            "ante\n",
            "el\n",
            "alcoyano\n",
            ",\n",
            "de\n",
            "segunda\n",
            "b\n",
            ",\n",
            "a\n",
            "pesar\n",
            "de\n",
            "empezar\n",
            "ganando\n",
            "y\n",
            "jugar\n",
            "con\n",
            "un\n",
            "hombre\n",
            "menos\n",
            "en\n",
            "la\n",
            "prórroga\n",
            ".\n",
            "el\n",
            "técnico\n",
            "francés\n",
            "dispuso\n",
            "un\n",
            "equipo\n",
            "plagado\n",
            "de\n",
            "los\n",
            "menos\n",
            "habituales\n",
            ",\n",
            "con\n",
            "vinicius\n",
            "y\n",
            "mariano\n",
            "en\n",
            "ataque\n",
            ".\n",
            "ninguno\n",
            "de\n",
            "los\n",
            "dos\n",
            "logró\n",
            "crear\n",
            "ocasiones\n",
            ".\n",
            "fue\n",
            "militao\n",
            "el\n",
            "que\n",
            "marcó\n",
            "el\n",
            "gol\n",
            "del\n",
            "madrid\n",
            ",\n",
            "justo\n",
            "antes\n",
            "del\n",
            "descanso\n",
            ".\n",
            "en\n",
            "la\n",
            "segunda\n",
            "parte\n",
            "intentaron\n",
            "cerrar\n",
            "el\n",
            "partido\n",
            ",\n",
            "pero\n",
            "sin\n",
            "el\n",
            "colmillo\n",
            "suficiente\n",
            "y\n",
            "el\n",
            "modesto\n",
            "alcoyano\n",
            "aprovechó\n",
            "un\n",
            "córner\n",
            "para\n",
            "empatar\n",
            "el\n",
            "partido\n",
            "a\n",
            "cinco\n",
            "minutos\n",
            "para\n",
            "el\n",
            "final\n",
            ".\n",
            "el\n",
            "empate\n",
            "sentó\n",
            "como\n",
            "un\n",
            "jarro\n",
            "de\n",
            "agua\n",
            "fría\n",
            "a\n",
            "los\n",
            "blancos\n",
            ",\n",
            "que\n",
            "lo\n",
            "intentaron\n",
            "en\n",
            "el\n",
            "tiempo\n",
            "extra\n",
            "a\n",
            "falta\n",
            "de\n",
            "cinco\n",
            "minutos\n",
            ",\n",
            "el\n",
            "casanova\n",
            "consiguió\n",
            "el\n",
            "gol\n",
            "más\n",
            "importante\n",
            "de\n",
            "su\n",
            "vida\n",
            ",\n",
            "que\n",
            "vale\n",
            "la\n",
            "clasificación\n",
            "para\n",
            "octavos\n",
            "de\n",
            "la\n",
            "copa\n",
            ".\n",
            "el\n",
            "madrid\n",
            "de\n",
            "zidane\n",
            "queda\n",
            "apeado\n",
            "del\n",
            "torneo\n",
            "una\n",
            "vez\n",
            "más\n",
            ",\n",
            "por\n",
            "lo\n",
            "que\n",
            "el\n",
            "francés\n",
            "se\n",
            "quedará\n",
            "sin\n",
            "pelear\n",
            "por\n",
            "el\n",
            "único\n",
            "título\n",
            "que\n",
            "no\n",
            "ha\n",
            "conseguido\n",
            "nunca\n",
            ".\n",
            "así\n",
            "hemos\n",
            "contado\n",
            "el\n",
            "minuto\n",
            "a\n",
            "minuto\n",
            "del\n",
            "partido\n",
            "en\n",
            "directo\n",
            ":\n"
          ]
        }
      ],
      "source": [
        "# Puedes insertar aquí código de pruebas para experimentar con las diferentes funciones y atributos de 'doc'.\n",
        "#print(data[\"CONTENIDO A ANALIZAR\"][1])\n",
        "#print(data[\"INTENSIDAD\"][1])\n",
        "doc = []\n",
        "value = []\n",
        "\n",
        "#con el bucle, generamos sendas listas con los comentarios ya parseados y con el valor de intensidad\n",
        "for i in range(0, lines_number):\n",
        "\n",
        "    #en un primer paso se parsea el comentario. En el segundo paso se añade el objeto a la lista\n",
        "    tmp_doc = nlp(data[\"CONTENIDO A ANALIZAR\"][i])\n",
        "    doc.append(tmp_doc)\n",
        "\n",
        "    #en un primer paso extrae el valor. En el segundo paso se añade el valor a la lista\n",
        "    tmp_value = data[\"INTENSIDAD\"][i]\n",
        "    value.append(tmp_value)\n",
        "\n",
        "\n",
        "#ejemplo de cómo recorrer un comentario palabra por palabra\n",
        "for token in doc[1]:\n",
        "    print(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thxi19cXFgcQ"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 1.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántos registros contiene el corpus?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZMknX6OFgcQ",
        "outputId": "dfdf0f21-a6b5-429a-cc4c-b7afce1bf4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El archivo CSV contiene 574915 registros.\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "num_registros = len(data)\n",
        "print(f\"El archivo CSV contiene {num_registros} registros.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPi88KDNFgcQ"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Se considera un registro cada fila del archivo CSV. Con la funcion len() se obtiene el numero de registros del dataset creado a partir del CSV.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpxIY1V0FgcR"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 2.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas palabras totales hay en los comentarios del corpus?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN4EhqVGFgcR",
        "outputId": "5391f22c-62aa-413f-8d57-a04277f5a6b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 334323/334323 [14:41<00:00, 379.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los comentarios del corpus contienen un total de 17845272 palabras.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "from tqdm import tqdm\n",
        "comentarios = data[data['TIPO DE MENSAJE'] == 'COMENTARIO']\n",
        "textos = comentarios['CONTENIDO A ANALIZAR'].dropna()\n",
        "\n",
        "components_to_disable = ['ner','parser','tok2vec','attribute_ruler','lemmatizer']\n",
        "with nlp.disable_pipes(*components_to_disable):\n",
        "  tqdm.pandas()\n",
        "  docs = nlp.pipe(textos, batch_size=1000, n_process=-1)\n",
        "\n",
        "  docs_progreso = tqdm(docs, total=len(textos))\n",
        "\n",
        "  num_palabras_totales = sum(len(doc) for doc in docs_progreso)\n",
        "\n",
        "print(f'Los comentarios del corpus contienen un total de {num_palabras_totales} palabras.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGhBX-6fFgcR"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Lo primero que se hace es filtrar los mensajes que son de tipo COMENTARIO y se guardan en la variable 'comentario'. Posteriormente se eliminan todos los mensajes nulos con la funcion <b>dropna()</b>.\n",
        "Una vez hecho esto se comienza el análisis con spaCy, para acelerar el proceso se hace uso de batch con pipes. La función <b>nlp.pipe()</b> permite procesar varios textos en paralelo mejorando el rendimiento ya que en este caso el corpus es de un tamaño considerable. Se han usado batch de 1000 textos por lote y todos los núcleos disponibles. También se han desactivado componentes del pipeline que no son necesarios para agilizar el procesamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q5PrvGeFgcR"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 3.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuál el número promedio de palabras en cada comentario?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFL8g22zFgcR",
        "outputId": "ad90e1e4-e4e5-4243-8d13-a2472c102610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El numero promedio de palabras por comentario es de 53.38\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "num_comentarios = len(comentarios)\n",
        "\n",
        "promedio_palabras = num_palabras_totales / num_comentarios\n",
        "print(f'El numero promedio de palabras por comentario es de {promedio_palabras:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-0jZ5onFgcS"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Para calcular el número promedio de palabras en cada comentario se utiliza el total de palabras del corpus obtenido en la pregunta 2 y se divide entre el número total de comentarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVNF1TlxFgcS"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 4.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál el número promedio de palabras en los comentarios de cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmZdOF0PFgcS",
        "outputId": "01dd90c6-83a0-4b0a-ed3f-5a2642e53476"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10621/10621 [00:23<00:00, 451.88it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Los comentarios de odio contienen un total de 193570 palabras.\n",
            "Los comentarios de odio tienen un numero promedio de 18.23 palabras\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "#COMENTARIOS ODIO\n",
        "from tqdm import tqdm\n",
        "\n",
        "comentarios = data[data['TIPO DE MENSAJE'] == 'COMENTARIO']\n",
        "comentarios.loc[:,'INTENSIDAD'] = pd.to_numeric(comentarios['INTENSIDAD'], errors='coerce')\n",
        "comentarios_odio = comentarios[comentarios['INTENSIDAD'] > 0]\n",
        "textos_odio = comentarios_odio['CONTENIDO A ANALIZAR'].dropna()\n",
        "\n",
        "components_to_disable = ['ner','parser','tok2vec','attribute_ruler','lemmatizer']\n",
        "with nlp.disable_pipes(*components_to_disable):\n",
        "  tqdm.pandas()\n",
        "  docs_odio = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "  docs_progreso_odio = tqdm(docs_odio, total=len(textos_odio))\n",
        "  num_palabras_odio = sum(len(doc) for doc in docs_progreso_odio)\n",
        "\n",
        "print(f'\\nLos comentarios de odio contienen un total de {num_palabras_odio} palabras.')\n",
        "\n",
        "num_comentarios_odio = len(comentarios_odio)\n",
        "promedio_palabras_odio = num_palabras_odio / num_comentarios_odio\n",
        "print(f'Los comentarios de odio tienen un numero promedio de {promedio_palabras_odio:.2f} palabras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WZT41c_F4g0",
        "outputId": "bd63920f-a047-43f9-9eac-2a50d001cac8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 323699/323699 [13:49<00:00, 390.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Los comentarios de no odio contienen un total de 17640317 palabras.\n",
            "Los comentarios de no odio tienen un numero promedio de 18.23 palabras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#COMENTARIOS NO ODIO\n",
        "from tqdm import tqdm\n",
        "\n",
        "comentarios_no_odio = comentarios[comentarios['INTENSIDAD'] == 0]\n",
        "textos_no_odio = comentarios_no_odio['CONTENIDO A ANALIZAR'].dropna()\n",
        "\n",
        "components_to_disable = ['ner','parser','tok2vec','attribute_ruler','lemmatizer']\n",
        "with nlp.disable_pipes(*components_to_disable):\n",
        "  tqdm.pandas()\n",
        "  docs_no_odio = nlp.pipe(textos_no_odio, batch_size=1000, n_process=-1)\n",
        "  docs_progreso_no_odio = tqdm(docs_no_odio, total=len(textos_no_odio))\n",
        "  num_palabras_no_odio = sum(len(doc) for doc in docs_progreso_no_odio)\n",
        "\n",
        "print(f'\\nLos comentarios de no odio contienen un total de {num_palabras_no_odio} palabras.')\n",
        "\n",
        "num_comentarios_no_odio = len(comentarios_no_odio)\n",
        "promedio_palabras_no_odio = num_palabras_no_odio / num_comentarios_no_odio\n",
        "\n",
        "print(f'Los comentarios de no odio tienen un numero promedio de {promedio_palabras_odio:.2f} palabras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bisLS8OFgcS"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Los comentarios de odio tienen un promedio de <b>18,23 palabras</b> por comentario y los comentarios sin odio tienen un promedio de <b>18,23 palabras por comentario</b>. Para ello se han dividido los comentarios en dos grupos 'comentarios_odio' y 'comentarios_no_odio' filtrando por la intensidad = 0 o > 0. Una vez obtenidos los dos datasets se utiliza un pipeline deshabilitando los componentes que no son necesarios para agilizar el procesamiento de los textos. En este caso han sido <b>['ner','parser','tok2vec','attribute_ruler','lemmatizer']</b>. Finalmente se divide el numero de palabras de cada grupo entre el número de comentarios de cada grupo para obtener la media.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0xkgG3sFgcT"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 5.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el número promedio de oraciones en los comentarios de cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw1B4KDMFgcT",
        "outputId": "15f013df-96e1-4a10-f821-dbbeb686f8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10621/10621 [00:16<00:00, 649.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Los comentarios de odio contienen un total de 16520 oraciones.\n",
            "Los comentarios de odio tiene un promedio de 1.56 oraciones por comentario.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "from tqdm import tqdm\n",
        "comentarios = data[data['TIPO DE MENSAJE'] == 'COMENTARIO']\n",
        "comentarios.loc[:,'INTENSIDAD'] = pd.to_numeric(comentarios['INTENSIDAD'], errors='coerce')\n",
        "comentarios_odio = comentarios[comentarios['INTENSIDAD'] > 0]\n",
        "textos_odio = comentarios_odio['CONTENIDO A ANALIZAR'].dropna()\n",
        "components_to_disable = ['ner']\n",
        "\n",
        "with nlp.disable_pipes(*components_to_disable):\n",
        "  tqdm.pandas()\n",
        "  docs_odio = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "  docs_progreso_odio = tqdm(docs_odio, total=len(textos_odio))\n",
        "  num_oraciones_odio = sum(len(list(doc.sents)) for doc in docs_progreso_odio)\n",
        "\n",
        "print(f'\\nLos comentarios de odio contienen un total de {num_oraciones_odio} oraciones.')\n",
        "print(f'Los comentarios de odio tiene un promedio de {num_oraciones_odio/len(comentarios_odio):.2f} oraciones por comentario.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww2spvH7Lss4",
        "outputId": "7c389c2c-f069-46f4-dae2-3836383ceb6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 323699/323699 [08:27<00:00, 638.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Los comentarios de no odio contienen un total de 734655 oraciones.\n",
            "Los comentarios de no odio tiene un promedio de 2.27 oraciones por comentario.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "comentarios_no_odio = comentarios[comentarios['INTENSIDAD'] == 0]\n",
        "textos_no_odio = comentarios_no_odio['CONTENIDO A ANALIZAR'].dropna()\n",
        "with nlp.disable_pipes(*components_to_disable):\n",
        "  tqdm.pandas()\n",
        "  docs_no_odio = nlp.pipe(textos_no_odio, batch_size=1000, n_process=-1)\n",
        "  docs_progreso_no_odio = tqdm(docs_no_odio, total=len(textos_no_odio))\n",
        "  num_oraciones_no_odio = sum(len(list(doc.sents)) for doc in docs_progreso_no_odio)\n",
        "\n",
        "print(f'\\nLos comentarios de no odio contienen un total de {num_oraciones_no_odio} oraciones.')\n",
        "print(f'Los comentarios de no odio tiene un promedio de {num_oraciones_no_odio/len(comentarios_no_odio):.2f} oraciones por comentario.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qqr0zrzFgcT"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Para obtener el número de oraciones haciendo uso del pipeline de spaCy, se hace uso de la propiedad <b>doc.sents</b> por cada documento procesado. En el pipeline se desactivan los componentes innecesarios para acelerar el procesamiento de los textos, en este caso se desactiva solo 'ner' para conservar 'parser' que es necesario para la detección de oraciones. Se procesan los textos mostrando la barra de progreso haciendo uso de la libreria tqdm y se cuenta el total de oraciones obteniendo un promedio de <b>1,56 oraciones</b> para los comentarios de odio y <b>2,27 oraciones</b> para los comentarios sin odio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2DRvkolFgcT"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 6.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de comentarios que contienen entidades NER en cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVZnpsksFgcT",
        "outputId": "24671b42-d491-4f3f-9440-daca76aa9ade"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10621/10621 [00:16<00:00, 661.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "El 34.35% de los comentarios de odio contienen entidades NER.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 323699/323699 [09:12<00:00, 586.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "El 46.10% de los comentarios de odio contienen entidades NER.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "docs = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_odio))\n",
        "num_comentarios_con_ner_odio = sum(1 for doc in docs_progreso if doc.ents)\n",
        "\n",
        "print(f'\\nEl {num_comentarios_con_ner_odio/len(textos_odio)*100:.2f}% de los comentarios de odio contienen entidades NER.')\n",
        "\n",
        "docs = nlp.pipe(textos_no_odio, batch_size=500, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_no_odio))\n",
        "num_comentarios_con_ner_no_odio = sum(1 for doc in docs_progreso if doc.ents)\n",
        "\n",
        "print(f'\\nEl {num_comentarios_con_ner_no_odio/len(textos_no_odio)*100:.2f}% de los comentarios de odio contienen entidades NER.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNI8aSaVFgcU"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Para calcular el porcentaje de comentarios que tienen al menos una entidad NER se hace uso del pipeline de spaCy con la funcionalidad de entidades <b>doc.ents</b>. Se devuelve un iterable con las NER en un documento, en caso de estar vacio significa que no hay entidades en ese comentario. Posteriormente se usa un generador para contar los documentos que contienen al menos una entidad NER. Para finalizar se calcula el porcentaje de comentarios que tienen entidades con la formula <b>((num_comentarios_con_ner_odio / len(textos_odio)*100)</b>.\n",
        "Como resultado se obtiene que el <b>34,35% de los comentarios de odio</b> y el <b>46,10% de comentarios sin odio</b> contienen entidades NER.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1AGUYnvFgcU"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 7.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de comentarios que contienen entidades NER de tipo PERSON en cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdHHqWWIFgcU",
        "outputId": "54e33e41-28b0-4b58-c8d9-73078f34d6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10621/10621 [00:15<00:00, 668.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El 18.80% de los comentarios de odio contienen entidades NER de tipo PERSON.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 323699/323699 [09:56<00:00, 542.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El 20.83% de los comentarios sin odio contienen entidades NER de tipo PERSON.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "comentarios_no_odio = comentarios[comentarios['INTENSIDAD'] == 0]\n",
        "textos_no_odio = comentarios_no_odio['CONTENIDO A ANALIZAR'].dropna()\n",
        "\n",
        "docs = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_odio))\n",
        "num_comentarios_con_ner_odio = sum(1 for doc in docs_progreso if any(ent.label_ == 'PER' for ent in doc.ents))\n",
        "\n",
        "print(f'\\nEl {num_comentarios_con_ner_odio/len(textos_odio)*100:.2f}% de los comentarios de odio contienen entidades NER de tipo PERSON.')\n",
        "\n",
        "docs = nlp.pipe(textos_no_odio, batch_size=1000, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_no_odio))\n",
        "num_comentarios_con_ner_no_odio = sum(1 for doc in docs_progreso if any(ent.label_ == 'PER' for ent in doc.ents))\n",
        "\n",
        "print(f'\\nEl {num_comentarios_con_ner_no_odio/len(textos_no_odio)*100:.2f}% de los comentarios sin odio contienen entidades NER de tipo PERSON.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5IExPBhFgcU"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Para obtener el procentaje de comentarios que contienen al menos una entidad NER de tipo PERSON se extiende el código implementado en la pregunta 6 filtrando exclusivamente para este tipo de entidad. Cada entidad tiene un atributo .label_ que indica su tipo. El tipo PERSON se usa para identificar nombres de personas. Para filtrar por entidades PERSON se usa <b>any(ent.label_ == 'PERSON' for ent in doc.ents)</b> comprobando asi si alguna de las entidades en el doc es de tipo PERSON. En el caso de cumplir la condición se suma uno al contador num_comentarios_con_person_odio en el caso de comentarios con odio y lo mismo para los comentarios sin odio.\n",
        "Como resultado se obtiene que el <b>18,80% de los comentarios de odio</b> y el <b>0% de los comentarios sin odio</b> contienen al menos una entidad PERSON.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzfP_FXHFgcU"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 8.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de palabras en cada combinación posible de género y número (p.ej. masculino singular) en cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2mLtQYHFgcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f264863-b528-4476-cc53-23176f51bd69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10621/10621 [00:16<00:00, 627.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Porcentaje de palabras por combinación de género y número en los comentarios de odio:\n",
            "\n",
            "Masc Sing: 13.75%\n",
            "\n",
            "Fem Sing: 11.32%\n",
            "\n",
            "Masc Plur: 6.37%\n",
            "\n",
            "Fem Plur: 2.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 323699/323699 [10:42<00:00, 503.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Porcentaje de palabras por combinación de género y número en los comentarios sin odio:\n",
            "\n",
            "Masc Sing: 14.61%\n",
            "\n",
            "Fem Sing: 11.65%\n",
            "\n",
            "Masc Plur: 5.76%\n",
            "\n",
            "Fem Plur: 3.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "from collections import Counter\n",
        "\n",
        "docs = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_odio))\n",
        "\n",
        "genero_numero_contador = Counter()\n",
        "palabras_totales = 0\n",
        "for doc in docs_progreso:\n",
        "  for token in doc:\n",
        "    genero = token.morph.get(\"Gender\")\n",
        "    numero = token.morph.get(\"Number\")\n",
        "    if genero and numero:\n",
        "      genero_numero_contador[(genero[0], numero[0])] += 1\n",
        "    palabras_totales += 1\n",
        "\n",
        "porcentajes = {key: (count / palabras_totales)*100 for key, count in genero_numero_contador.items()}\n",
        "\n",
        "print(f'\\nPorcentaje de palabras por combinación de género y número en los comentarios de odio:')\n",
        "for(genero, numero), porcentaje in porcentajes.items():\n",
        "  print(f'\\n{genero} {numero}: {porcentaje:.2f}%')\n",
        "\n",
        "\n",
        "docs = nlp.pipe(textos_no_odio, batch_size=700, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_no_odio))\n",
        "\n",
        "genero_numero_contador = Counter()\n",
        "palabras_totales = 0\n",
        "for doc in docs_progreso:\n",
        "  for token in doc:\n",
        "    genero = token.morph.get(\"Gender\")\n",
        "    numero = token.morph.get(\"Number\")\n",
        "    if genero and numero:\n",
        "      genero_numero_contador[(genero[0], numero[0])] += 1\n",
        "    palabras_totales += 1\n",
        "\n",
        "porcentajes = {key: (count / palabras_totales)*100 for key, count in genero_numero_contador.items()}\n",
        "\n",
        "print(f'\\nPorcentaje de palabras por combinación de género y número en los comentarios sin odio:')\n",
        "for(genero, numero), porcentaje in porcentajes.items():\n",
        "  print(f'\\n{genero} {numero}: {porcentaje:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMFO0gaMFgcV"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Para calcular el porcentaje de palabras en cada combinación de género y número en los comentarios, se usa el atributo <b>token.morph</b> de los tokens en spaCy, que contienen información morfológica y se filtran segun su género y número. Cuando se extraen las caracteristicas morfológicas del token se usa 'Gender' y 'Number'. Se cuenta la cantidad de tokens con cada combinación de género y número y se calcula el porcentaje dividiendo el conteo entre el total de palabras y multiplicando por 100.\n",
        "Como resultado se obtiene:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I9m0SNYFgcV"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 9.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio), indica cuántas entidades de cada tipo posible se reconocen en cada uno de los grupos</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNCcUjhNFgca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be751434-fe42-46f0-ad9f-be2eba92c424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10621/10621 [00:15<00:00, 671.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conteo de entidades por tipo en los comentarios de odio:\n",
            "\n",
            "PER: 2300\n",
            "\n",
            "MISC: 902\n",
            "\n",
            "ORG: 526\n",
            "\n",
            "LOC: 1084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 323699/323699 [09:18<00:00, 579.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conteo de entidades por tipo en los comentarios sin odio:\n",
            "\n",
            "ORG: 53245\n",
            "\n",
            "MISC: 58914\n",
            "\n",
            "PER: 148768\n",
            "\n",
            "LOC: 176677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "from collections import Counter\n",
        "\n",
        "docs = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_odio))\n",
        "\n",
        "contador_tipo_entidades = Counter()\n",
        "\n",
        "for doc in docs_progreso:\n",
        "  contador_tipo_entidades.update([ent.label_ for ent in doc.ents])\n",
        "\n",
        "print(f'\\nConteo de entidades por tipo en los comentarios de odio:')\n",
        "for tipo_entidad, cuenta in contador_tipo_entidades.items():\n",
        "  print(f'\\n{tipo_entidad}: {cuenta}')\n",
        "\n",
        "docs = nlp.pipe(textos_no_odio, batch_size=700, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_no_odio))\n",
        "\n",
        "contador_tipo_entidades = Counter()\n",
        "\n",
        "for doc in docs_progreso:\n",
        "  contador_tipo_entidades.update([ent.label_ for ent in doc.ents])\n",
        "\n",
        "print(f'\\nConteo de entidades por tipo en los comentarios sin odio:')\n",
        "for tipo_entidad, cuenta in contador_tipo_entidades.items():\n",
        "  print(f'\\n{tipo_entidad}: {cuenta}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_pt8MdMFgcb"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Para obtener las entidades de cada tipo en los dos grupos se usa el <b>Counter()</b> para contar las etiquetas de las entidades <b>(ent.label_)</b> en todos los textos procesados. En este caso se obtienen las entidades de tipo <b>PERSON, ORGANIZATION, LOCATION y MISCELLANEOUS</b>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYRZ3ltoFgcb"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 10.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio), extrae y muestra los 100 lemas más repetidos en los comentarios de cada grupo</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx38uHMAFgcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bb1690-8495-4b00-9e11-3034288a1af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10621/10621 [00:16<00:00, 652.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Los 100 lemas más repetidos en los comentarios de odio:\n",
            "1. mierda: 758\n",
            "2. \r\n",
            ": 725\n",
            "3. puta: 657\n",
            "4. asco: 503\n",
            "5.  : 468\n",
            "6. gobierno: 453\n",
            "7. q: 384\n",
            "8. hijo: 381\n",
            "9. españa: 376\n",
            "10. mentiroso: 369\n",
            "11. país: 366\n",
            "12. panfleto: 347\n",
            "13. gente: 345\n",
            "14. vergüenza: 330\n",
            "15. gentuza: 299\n",
            "16. basura: 297\n",
            "17.  : 290\n",
            "18. español: 265\n",
            "19. tonto: 253\n",
            "20. político: 239\n",
            "21. miserable: 239\n",
            "22. dejar: 226\n",
            "23. pasar: 223\n",
            "24. gilipol él: 219\n",
            "25. puto: 216\n",
            "26. pagar: 204\n",
            "27. ver: 201\n",
            "28. mundo: 194\n",
            "29. inútil: 191\n",
            "30. facha: 189\n",
            "31. culo: 189\n",
            "32. tener: 187\n",
            "33. año: 186\n",
            "34. salir: 184\n",
            "35. madre: 180\n",
            "36. decir: 177\n",
            "37. idiota: 177\n",
            "38. \r\n",
            "\r\n",
            ": 176\n",
            "39. terrorista: 174\n",
            "40. seguir: 170\n",
            "41. sinvergüenza: 169\n",
            "42. dinero: 167\n",
            "43. dar: 167\n",
            "44. vida: 167\n",
            "45. informativo: 167\n",
            "46. haber: 160\n",
            "47. fascista: 160\n",
            "48. noticia: 156\n",
            "49. poner: 155\n",
            "50. querer: 155\n",
            "51. ir: 152\n",
            "52. cara: 150\n",
            "53. menudo: 150\n",
            "54. cárcel: 147\n",
            "55. madrid: 144\n",
            "56. tomar: 143\n",
            "57. hdp: 143\n",
            "58.   : 139\n",
            "59. payaso: 138\n",
            "60. @lavanguardia: 138\n",
            "61. hdlgp: 137\n",
            "62. esperar: 135\n",
            "63. mujer: 134\n",
            "64. asesino: 134\n",
            "65. importar: 134\n",
            "66. persona: 133\n",
            "67. panda: 132\n",
            "68. sinvergüenzas: 131\n",
            "69. quedar: 129\n",
            "70. comunista: 129\n",
            "71. creer: 128\n",
            "72. jeta: 128\n",
            "73. asqueroso: 127\n",
            "74. vivir: 126\n",
            "75. izquierda: 124\n",
            "76. deber: 124\n",
            "77. cosa: 123\n",
            "78. terrorismo: 123\n",
            "79. mentira: 122\n",
            "80. pensar: 122\n",
            "81. partido: 120\n",
            "82. acabar: 120\n",
            "83. sánchez: 118\n",
            "84. vox: 117\n",
            "85. votar: 117\n",
            "86. venir: 116\n",
            "87. vacuna: 113\n",
            "88. hacer: 112\n",
            "89. calle: 108\n",
            "90. maldito: 107\n",
            "91. catalán: 106\n",
            "92. periodismo: 106\n",
            "93. llegar: 105\n",
            "94. corrupto: 104\n",
            "95. trump: 104\n",
            "96. llamar: 103\n",
            "97. culpa: 102\n",
            "98. dais: 102\n",
            "99. inutil: 102\n",
            "100. hablar: 101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "#COMENTARIOS CON ODIO\n",
        "docs = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_odio))\n",
        "\n",
        "contador_lemas = Counter()\n",
        "\n",
        "for doc in docs_progreso:\n",
        "  contador_lemas.update(token.lemma_.lower() for token in doc if not token.is_punct and not token.is_stop)\n",
        "\n",
        "lemas_comunes = contador_lemas.most_common(100)\n",
        "\n",
        "print(\"\\nLos 100 lemas más repetidos en los comentarios de odio:\")\n",
        "for i, (lema, frecuencia) in enumerate(lemas_comunes, 1):\n",
        "    print(f\"{i}. {lema}: {frecuencia}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOLUXY2Fz63W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c556c33-c663-4790-fd47-7cb702f310d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 323699/323699 [09:56<00:00, 542.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los 100 lemas más repetidos en los comentarios sin odio:\n",
            "1. año: 32567\n",
            "2.  : 27880\n",
            "3. gobierno: 26895\n",
            "4. \r\n",
            ": 23984\n",
            "5.  : 22941\n",
            "6. españa: 22595\n",
            "7. persona: 21663\n",
            "8. caso: 19210\n",
            "9. país: 18318\n",
            "10. ver: 18223\n",
            "11. pasar: 15644\n",
            "12. madrid: 15193\n",
            "13. gente: 15145\n",
            "14. seguir: 14452\n",
            "15. vacuna: 13813\n",
            "16. millón: 13434\n",
            "17. español: 13285\n",
            "18. haber: 13257\n",
            "19. querer: 13027\n",
            "20. dejar: 12945\n",
            "21. poner: 12692\n",
            "22. público: 12407\n",
            "23. tener: 12403\n",
            "24. poder: 12063\n",
            "25. llegar: 12043\n",
            "26. pandemia: 11730\n",
            "27. salir: 11722\n",
            "28. político: 11560\n",
            "29. hora: 11467\n",
            "30. cosa: 11361\n",
            "31. decir: 11199\n",
            "32. comunidad: 11103\n",
            "33.   : 11016\n",
            "34. quedar: 11010\n",
            "35. tiempo: 11005\n",
            "36. medida: 11000\n",
            "37. vida: 10565\n",
            "38. mundo: 10432\n",
            "39. euros: 10372\n",
            "40. mes: 10332\n",
            "41. centro: 10289\n",
            "42. deber: 9998\n",
            "43. partido: 9828\n",
            "44. social: 9684\n",
            "45. momento: 9466\n",
            "46. pedir: 9391\n",
            "47. pagar: 9338\n",
            "48. q: 9299\n",
            "49. esperar: 9290\n",
            "50. semana: 9221\n",
            "51. ir: 9114\n",
            "52. problema: 9034\n",
            "53. servicio: 8993\n",
            "54. estar: 8858\n",
            "55. vivir: 8840\n",
            "56. casa: 8802\n",
            "57. venir: 8800\n",
            "58. sanitario: 8774\n",
            "59. i: 8719\n",
            "60. hacer: 8648\n",
            "61. situación: 8648\n",
            "62. trump: 8528\n",
            "63. trabajo: 8461\n",
            "64. forma: 8460\n",
            "65. empresa: 8385\n",
            "66. llevar: 8374\n",
            "67. presidente: 8363\n",
            "68. pp: 8033\n",
            "69. pensar: 7888\n",
            "70. trabajar: 7888\n",
            "71. hospital: 7789\n",
            "72. volver: 7748\n",
            "73. dar: 7685\n",
            "74. mujer: 7523\n",
            "75. salud: 7383\n",
            "76. ciudadano: 7196\n",
            "77. zona: 6974\n",
            "78. medio: 6971\n",
            "79. creer: 6945\n",
            "80. dinero: 6917\n",
            "81. hablar: 6812\n",
            "82. mantener: 6752\n",
            "83. explicar: 6682\n",
            "84. dato: 6645\n",
            "85. grupo: 6608\n",
            "86. ley: 6580\n",
            "87. ciudad: 6511\n",
            "88. permitir: 6510\n",
            "89. entender: 6503\n",
            "90. recibir: 6467\n",
            "91. tomar: 6450\n",
            "92. calle: 6430\n",
            "93. catalán: 6406\n",
            "94. derecho: 6403\n",
            "95. hombre: 6372\n",
            "96. covid: 6354\n",
            "97. dosis: 6354\n",
            "98. acabar: 6339\n",
            "99. falta: 6310\n",
            "100. votar: 6146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#COMENTARIOS SIN ODIO\n",
        "docs = nlp.pipe(textos_no_odio, batch_size=1000, n_process=-1)\n",
        "docs_progreso = tqdm(docs, total=len(textos_no_odio))\n",
        "\n",
        "contador_lemas = Counter()\n",
        "\n",
        "for doc in docs_progreso:\n",
        "  contador_lemas.update(token.lemma_.lower() for token in doc if not token.is_punct and not token.is_stop)\n",
        "\n",
        "lemas_comunes = contador_lemas.most_common(100)\n",
        "\n",
        "print(\"Los 100 lemas más repetidos en los comentarios sin odio:\")\n",
        "for i, (lema, frecuencia) in enumerate(lemas_comunes, 1):\n",
        "    print(f\"{i}. {lema}: {frecuencia}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRjAz6HBFgcb"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Para extraer los 100 lemas más repetidos en los comentarios se utiliza el atributo <b>token.lemma_</b>.<br>El <b>token.is_punct</b> ignora los tokens que son signos de puntuación, el <b>token.is_stop</b> ignora las stop words y <b>token.lemma_.lower()</b> extrae el lema en minusculas para evitar duplicados. Con el método <b>Counter()</b> se almacena la frecuencia de cada lema en todos los comentarios y posteriormente con el método <b>most_common(100)</b> se seleccionan los 100 más frecuentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w77Y5DsZFgcb"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 11.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Es posible utilizar alguna de las características extraídas en las preguntas anteriores para determinar si un mensaje contiene odio? Justifica tu respuesta con el análisis estadístico que consideres necesario.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-14nY_8Fgcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29d644d-acde-419e-cf94-68b96d2897b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10621"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "from sklearn.utils import resample\n",
        "\n",
        "comentarios = data[data['TIPO DE MENSAJE'] == 'COMENTARIO']\n",
        "comentarios.loc[:,'INTENSIDAD'] = pd.to_numeric(comentarios['INTENSIDAD'], errors='coerce')\n",
        "\n",
        "comentarios_odio = comentarios[comentarios['INTENSIDAD'] > 0]\n",
        "textos_odio = comentarios_odio['CONTENIDO A ANALIZAR'].dropna()\n",
        "\n",
        "comentarios_no_odio = comentarios[comentarios['INTENSIDAD'] == 0]\n",
        "textos_no_odio = comentarios_no_odio['CONTENIDO A ANALIZAR'].dropna()\n",
        "\n",
        "textos_no_odio_balanceados = resample(textos_no_odio, replace=True, n_samples=len(textos_odio), random_state=42)\n",
        "textos_no_odio_balanceados.count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "num_palabras_odio = sum(len(doc) for doc in docs)\n",
        "\n",
        "docs = nlp.pipe(textos_no_odio_balanceados, batch_size=1000, n_process=-1)\n",
        "num_palabras_no_odio_b = sum(len(doc) for doc in docs)\n",
        "\n",
        "print(f'Número de palabras en mensajes de odio: {num_palabras_odio}')\n",
        "print(f'Número de palabras en mensajes de no odio balanceados: {num_palabras_no_odio_b}')\n",
        "print(f'Media de palabras en comentarios de odio: {num_palabras_odio / len(textos_odio):.2f}')\n",
        "print(f'Media de palabras en comentarios de no odio: {num_palabras_no_odio_b / len(textos_no_odio_balanceados):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVZD61qqV1IZ",
        "outputId": "259e356e-b86e-483c-db41-0bbe8ee0e19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de palabras en mensajes de odio: 193570\n",
            "Número de palabras en mensajes de no odio balanceados: 582425\n",
            "Media de palabras en comentarios de odio: 18.23\n",
            "Media de palabras en comentarios de no odio: 54.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = nlp.pipe(textos_odio, batch_size=1000, n_process=-1)\n",
        "num_comentarios_con_ner_odio = sum(1 for doc in docs if any(ent.label_ == 'PER' for ent in doc.ents))\n",
        "\n",
        "print(f'\\nEl {num_comentarios_con_ner_odio/len(textos_odio)*100:.2f}% de los comentarios de odio contienen entidades NER de tipo PERSON.')\n",
        "\n",
        "docs = nlp.pipe(textos_no_odio_balanceados, batch_size=1000, n_process=-1)\n",
        "num_comentarios_con_ner_no_odio = sum(1 for doc in docs if any(ent.label_ == 'PER' for ent in doc.ents))\n",
        "\n",
        "print(f'\\nEl {num_comentarios_con_ner_no_odio/len(textos_no_odio_balanceados)*100:.2f}% de los comentarios sin odio contienen entidades NER de tipo PERSON.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_yFyg--bS7G",
        "outputId": "1cfbe53c-c5b3-4cd3-e355-930ce5b9f631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El 18.80% de los comentarios de odio contienen entidades NER de tipo PERSON.\n",
            "\n",
            "El 20.54% de los comentarios sin odio contienen entidades NER de tipo PERSON.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOzP_t_cFgcc"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n",
        "Al balancear los datos y realizar la media de palabras de cada grupo se obtiene que los mensajes de odio tienen un promedio de 18,23 palabras y los mensajes sin odio un promedio de 54,84 palabras. Esto sugiere que, en promedio, los mensajes de odio son más breves o con menos elaboración que los mensajes sin odio.<br>\n",
        "En cuanto a las entidades NER de tipo PERSON, la diferencia entre ambos grupos es poco significativa, aproximadamente de 1,74%. Esto indica que la presencia de nombres propios no parece ser un indicador para distinguir entre mensajes de odio y no odio.<br>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}